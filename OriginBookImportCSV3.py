import pandas as pd
import os
import json
import originpro as op
import sys
import re
import warnings

warnings.filterwarnings('ignore')

class OriginDataProcessor:
    """é€šç”¨Originæ•°æ®å¤„ç†ä¸ç»˜å›¾ç±»"""

    def __init__(self):
        self.wb = None
        self.wks = None
        self.graph = None
        self.project_opened = False
        self.column_units = {}  # å­˜å‚¨åˆ—ååˆ°å•ä½çš„æ˜ å°„
        self.column_order_from_dataname = []  # DataNameè¡Œå®šä¹‰çš„åˆ—é¡ºåº

    def get_safe_filename(self, filename, max_length=30):
        """è·å–å®‰å…¨çš„å·¥ä½œç°¿åç§°"""
        base_name = os.path.splitext(filename)[0]
        safe_name = re.sub(r'[^\w\s\-]', '_', base_name)
        safe_name = re.sub(r'_+', '_', safe_name)

        if len(safe_name) > max_length:
            safe_name = safe_name[:max_length]

        if safe_name and safe_name[0].isdigit():
            safe_name = 'Data_' + safe_name

        if not safe_name or safe_name.isspace():
            safe_name = 'DataBook'

        return safe_name.strip()

    def is_origin_project_file(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯Originå·¥ç¨‹æ–‡ä»¶"""
        if not file_path:
            return False

        valid_extensions = ['.opj', '.opju', '.ogg', '.ogw', '.otp', '.otpu']
        ext = os.path.splitext(file_path)[1].lower()
        return ext in valid_extensions

    def find_origin_project(self, project_path):
        """æ™ºèƒ½æŸ¥æ‰¾Originå·¥ç¨‹æ–‡ä»¶"""
        if not project_path:
            return None, False

        if os.path.exists(project_path):
            return project_path, True

        base_name = os.path.splitext(project_path)[0]
        possible_extensions = ['.opju', '.opj', '.ogg', '.ogw']

        for ext in possible_extensions:
            test_path = base_name + ext
            if os.path.exists(test_path):
                print(f"ğŸ” æ‰¾åˆ°å·¥ç¨‹æ–‡ä»¶: {test_path}")
                return test_path, True

        dir_path = os.path.dirname(project_path) or '.'
        if os.path.exists(dir_path):
            for file in os.listdir(dir_path):
                file_base = os.path.splitext(file)[0]
                if file_base == os.path.basename(base_name):
                    full_path = os.path.join(dir_path, file)
                    if self.is_origin_project_file(full_path):
                        print(f"ğŸ” æ‰¾åˆ°åŒ¹é…çš„å·¥ç¨‹æ–‡ä»¶: {full_path}")
                        return full_path, True

        return project_path, False

    def load_config(self, config_path):
        """åŠ è½½ç»˜å›¾é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ '{config_path}' ä¸å­˜åœ¨")
            return None

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            config = {}

            if content.startswith('{'):
                config = json.loads(content)
            else:
                for pair in content.split(','):
                    if ':' in pair:
                        key, value = pair.split(':', 1)
                        key = key.strip()
                        value = value.strip()

                        if key == 'NeedCol' and '|' in value:
                            config[key] = [col.strip() for col in value.split('|')]
                        else:
                            config[key] = value

            required_keys = ['data_file', 'X', 'Y']
            missing_keys = [key for key in required_keys if key not in config]

            if missing_keys:
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_keys}")
                print(f"å¿…éœ€å­—æ®µ: {required_keys}")
                return None

            if 'project' not in config:
                config['project'] = None

            if 'output_dir' not in config:
                data_dir = os.path.dirname(os.path.abspath(config['data_file']))
                config['output_dir'] = data_dir

            if 'NeedCol' in config:
                if isinstance(config['NeedCol'], str):
                    config['NeedCol'] = [col.strip() for col in config['NeedCol'].split(',')]
                elif not isinstance(config['NeedCol'], list):
                    print(f"âš ï¸  NeedColæ ¼å¼é”™è¯¯ï¼Œå°†æå–å…¨éƒ¨åˆ—")
                    del config['NeedCol']

            if config['project']:
                actual_project_path, project_exists = self.find_origin_project(config['project'])
                config['project'] = actual_project_path
                config['project_exists'] = project_exists
            else:
                config['project_exists'] = False

            config = self._resolve_paths(config)

            print(f"âœ… æˆåŠŸåŠ è½½é…ç½®ï¼š")
            print(f"   æ•°æ®æ–‡ä»¶: {config['data_file']}")
            print(f"   Xè½´åˆ—: {config['X']}")
            print(f"   Yè½´åˆ—: {config['Y']}")
            if 'NeedCol' in config:
                print(f"   éœ€æå–çš„åˆ—: {config['NeedCol']}")
            else:
                print(f"   éœ€æå–çš„åˆ—: å…¨éƒ¨åˆ—")

            if config['project']:
                project_status = "å·²å­˜åœ¨" if config['project_exists'] else "å°†åˆ›å»º"
                print(f"   å·¥ç¨‹æ–‡ä»¶: {config['project']} ({project_status})")
            else:
                print(f"   å·¥ç¨‹æ–‡ä»¶: æ–°å»ºå·¥ç¨‹")

            print(f"   è¾“å‡ºç›®å½•: {config['output_dir']}")

            return config

        except Exception as e:
            print(f"âŒ è§£æé…ç½®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")
            return None

    def _resolve_paths(self, config):
        """è§£æé…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„"""
        if hasattr(self, '_config_dir'):
            config_dir = self._config_dir
        else:
            config_dir = os.getcwd()

        if 'data_file' in config:
            data_path = config['data_file']
            if not os.path.isabs(data_path):
                data_path = os.path.join(config_dir, data_path)
            config['data_file'] = os.path.abspath(data_path)

        if 'output_dir' in config:
            output_path = config['output_dir']
            if not os.path.isabs(output_path):
                output_path = os.path.join(config_dir, output_path)
            config['output_dir'] = os.path.abspath(output_path)
            os.makedirs(config['output_dir'], exist_ok=True)

        return config

    def read_data_file(self, file_path, need_columns=None):
        """
        è¯»å–æ•°æ®æ–‡ä»¶ï¼Œå¤„ç†å¤æ‚çš„åŒåˆ—åå®šä¹‰æ ¼å¼
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            return None, None, False

        print(f"ğŸ“‚ å¼€å§‹è§£ææ–‡ä»¶: {os.path.basename(file_path)}")
        print(f"   æ–‡ä»¶æ€»è¡Œæ•°: {len(lines)}")

        self.column_units.clear()
        self.column_order_from_dataname.clear()

        # 1. é¦–å…ˆæ‰¾åˆ°AnalysisSetup...Datum.Nameè¡Œæå–å•ä½æ˜ å°„
        datum_name_headers = []
        unit_mapping = {}

        for i, line in enumerate(lines):
            line = line.strip()

            if line.startswith('AnalysisSetup') and 'Datum.Name' in line:
                print(f"ğŸ“‹ æ‰¾åˆ°AnalysisSetup...Datum.Nameè¡Œ (ç¬¬{i + 1}è¡Œ)")

                # æ£€æµ‹åˆ†éš”ç¬¦
                delimiter = self._detect_delimiter(line)
                print(f"   æ£€æµ‹åˆ°åˆ†éš”ç¬¦: '{delimiter}'")

                parts = line.split(delimiter)
                print(f"   åˆ†å‰²ç»“æœ: {parts}")

                if len(parts) > 2:
                    datum_name_headers = [h.strip() for h in parts[2:] if h.strip()]
                    print(f"   AnalysisSetupåˆ—å: {datum_name_headers}")

                    # æŸ¥æ‰¾å¯¹åº”çš„å•ä½è¡Œ
                    for j in range(i + 1, min(i + 10, len(lines))):
                        unit_line = lines[j].strip()
                        if unit_line.startswith('AnalysisSetup') and 'Datum.Unit' in unit_line:
                            print(f"ğŸ“ æ‰¾åˆ°å¯¹åº”çš„å•ä½è¡Œ (ç¬¬{j + 1}è¡Œ)")
                            unit_parts = unit_line.split(delimiter)

                            if len(unit_parts) > 2:
                                units = [u.strip() for u in unit_parts[2:] if u.strip()]
                                print(f"   å•ä½: {units}")

                                # åˆ›å»ºåˆ—å->å•ä½çš„æ˜ å°„
                                for col, unit in zip(datum_name_headers, units):
                                    unit_mapping[col] = unit
                                    print(f"   {col} -> {unit}")
                            break
                break

        # 2. æ‰¾åˆ°DataNameè¡Œï¼ˆè¿™æ˜¯å®é™…çš„åˆ—é¡ºåºï¼‰
        data_start_line = -1
        data_headers = []
        delimiter = ','  # é»˜è®¤é€—å·åˆ†éš”

        for i, line in enumerate(lines):
            line = line.strip()

            if line.startswith('DataName'):
                data_start_line = i
                print(f"\nğŸ“Š æ‰¾åˆ°DataNameè¡Œ (ç¬¬{i + 1}è¡Œ)")
                print(f"   è¡Œå†…å®¹: {line}")

                # æ£€æµ‹DataNameè¡Œçš„åˆ†éš”ç¬¦
                delimiter = self._detect_delimiter(line)
                print(f"   DataNameè¡Œåˆ†éš”ç¬¦: '{delimiter}'")

                parts = line.split(delimiter)
                data_headers = [h.strip() for h in parts[1:] if h.strip()]
                self.column_order_from_dataname = data_headers.copy()
                print(f"   DataNameåˆ—é¡ºåº: {data_headers}")
                print(f"   åˆ—æ•°: {len(data_headers)}")
                break

        if data_start_line == -1:
            print("âŒ æ–‡ä»¶ä¸­æœªæ‰¾åˆ°DataNameè¡Œ")
            return None, None, False

        # 3. å°†å•ä½æ˜ å°„åº”ç”¨åˆ°DataNameåˆ—çš„é¡ºåº
        for col in data_headers:
            if col in unit_mapping:
                self.column_units[col] = unit_mapping[col]

        print(f"\nğŸ“ æœ€ç»ˆåˆ—å•ä½æ˜ å°„:")
        for col in data_headers:
            unit = self.column_units.get(col, '[æ— å•ä½]')
            print(f"   {col}: {unit}")

        # 4. ç¡®å®šéœ€è¦æå–çš„åˆ—
        if need_columns:
            valid_columns = []
            missing_columns = []

            for col in need_columns:
                if col in data_headers:
                    valid_columns.append(col)
                else:
                    missing_columns.append(col)

            if missing_columns:
                print(f"âš ï¸  ä»¥ä¸‹éœ€è¦çš„åˆ—åœ¨æ–‡ä»¶ä¸­ä¸å­˜åœ¨: {missing_columns}")
                print(f"   å¯ç”¨åˆ—: {data_headers}")
                print(f"   å°†æå–æ–‡ä»¶ä¸­å®é™…å­˜åœ¨çš„åˆ—")

            if valid_columns:
                headers = valid_columns
                col_indices = [data_headers.index(col) for col in valid_columns]
                print(f"âœ… å°†æå– {len(valid_columns)} åˆ—: {valid_columns}")
                print(f"   åˆ—ç´¢å¼•: {col_indices}")
            else:
                print(f"âš ï¸  æ‰€æœ‰æŒ‡å®šåˆ—éƒ½ä¸å­˜åœ¨ï¼Œå°†æå–æ‰€æœ‰åˆ—")
                headers = data_headers
                col_indices = list(range(len(data_headers)))
        else:
            headers = data_headers
            col_indices = list(range(len(data_headers)))
            print(f"âœ… å°†æå–æ‰€æœ‰ {len(headers)} åˆ—")

        # 5. æ”¶é›†æ‰€æœ‰DataValueè¡Œæ•°æ®
        data_rows = []
        skipped_rows = 0
        data_row_count = 0

        print(f"\nğŸ“¥ å¼€å§‹è¯»å–DataValueæ•°æ®...")

        for i in range(data_start_line + 1, len(lines)):
            line = lines[i].strip()

            if not line:
                skipped_rows += 1
                continue

            if line.startswith(('SetupTitle', 'PrimitiveTest', 'TestParameter',
                                'AnalysisSetup', 'Dimension1', 'Dimension2', '#')):
                skipped_rows += 1
                continue

            if not line.startswith('DataValue'):
                print(f"âš ï¸  ç¬¬{i + 1}è¡Œä¸æ˜¯DataValueè¡Œï¼Œè·³è¿‡: {line[:50]}...")
                skipped_rows += 1
                continue

            # è§£æDataValueè¡Œ
            parts = line.split(delimiter)

            if len(parts) < 2:
                print(f"âš ï¸  ç¬¬{i + 1}è¡ŒDataValueæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                skipped_rows += 1
                continue

            # è·³è¿‡ç¬¬ä¸€ä¸ª"DataValue"ï¼Œè·å–æ•°æ®
            values = parts[1:]

            # æ¸…ç†æ•°æ®
            cleaned_values = []
            for val in values:
                cleaned_val = val.strip()
                # å¤„ç†ç§‘å­¦è®¡æ•°æ³•ä¸­çš„ç©ºæ ¼
                if ' ' in cleaned_val and ('E' in cleaned_val or 'e' in cleaned_val):
                    cleaned_val = cleaned_val.replace(' ', '')
                cleaned_values.append(cleaned_val)

            # æ£€æŸ¥æ•°æ®è¡Œæ˜¯å¦è¶³å¤Ÿé•¿
            if len(cleaned_values) < len(data_headers):
                print(f"âš ï¸  ç¬¬{i + 1}è¡Œæ•°æ®åˆ—æ•°ä¸è¶³ ({len(cleaned_values)} < {len(data_headers)})")
                # ç”¨ç©ºå€¼å¡«å……ä¸è¶³çš„éƒ¨åˆ†
                cleaned_values.extend([''] * (len(data_headers) - len(cleaned_values)))

            # æå–æŒ‡å®šåˆ—çš„æ•°æ®
            selected_values = []
            for idx in col_indices:
                if idx < len(cleaned_values):
                    selected_values.append(cleaned_values[idx])
                else:
                    selected_values.append('')

            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®
            has_data = any(val.strip() for val in selected_values)
            if has_data:
                data_rows.append(selected_values)
                data_row_count += 1

                if data_row_count <= 3:
                    print(f"   ç¬¬{i + 1}è¡Œæ•°æ®ç¤ºä¾‹: {selected_values}")
            else:
                skipped_rows += 1

        if not data_rows:
            print("âŒ æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„DataValueæ•°æ®")
            return None, None, False

        print(f"\nğŸ“ˆ æ•°æ®è¯»å–ç»Ÿè®¡:")
        print(f"   æˆåŠŸè¯»å–æ•°æ®è¡Œ: {len(data_rows)}")
        print(f"   è·³è¿‡çš„è¡Œ: {skipped_rows}")

        # 6. åˆ›å»ºDataFrame
        try:
            print(f"\nğŸ”„ åˆ›å»ºDataFrame...")
            df = pd.DataFrame(data_rows, columns=headers)
            print(f"   DataFrameåˆ›å»ºæˆåŠŸï¼Œå½¢çŠ¶: {df.shape}")

            # è½¬æ¢æ•°æ®ç±»å‹
            print(f"ğŸ”„ è½¬æ¢æ•°æ®ç±»å‹...")
            for col in headers:
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    non_null = df[col].count()
                    null_count = len(df) - non_null
                    if null_count > 0:
                        print(f"   {col}: æ•°å€¼ç±»å‹, {null_count}ä¸ªç©ºå€¼")
                    else:
                        print(f"   {col}: æ•°å€¼ç±»å‹")
                except:
                    print(f"   {col}: ä¿æŒä¸ºå­—ç¬¦ä¸²ç±»å‹")

            # æ•°æ®é¢„è§ˆ
            print(f"\nğŸ‘€ æ•°æ®é¢„è§ˆ (å‰3è¡Œ):")
            print(df.head(3).to_string())

            print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
            print(f"   æ€»è¡Œæ•°: {len(df)}")
            print(f"   æ€»åˆ—æ•°: {len(df.columns)}")
            print(f"   åˆ—å: {list(df.columns)}")

            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            if len(numeric_cols) > 0:
                print(f"   æ•°å€¼åˆ—ç»Ÿè®¡:")
                for col in numeric_cols:
                    col_data = df[col].dropna()
                    if len(col_data) > 0:
                        print(f"     {col}: èŒƒå›´=[{col_data.min():.4e}, {col_data.max():.4e}]")

            return df, headers, True

        except Exception as e:
            print(f"âŒ åˆ›å»ºDataFrameæ—¶å‡ºé”™ï¼š{e}")
            import traceback
            traceback.print_exc()
            return None, None, False

    def _detect_delimiter(self, line):
        """ä»è¡Œä¸­æ£€æµ‹åˆ†éš”ç¬¦"""
        if not line or not line.strip():
            return ','

        possible_delimiters = [',', '\t', ';', '|']
        delimiter_counts = {}

        for delim in possible_delimiters:
            count = line.count(delim)
            if count > 0:
                delimiter_counts[delim] = count

        if delimiter_counts:
            return max(delimiter_counts.items(), key=lambda x: x[1])[0]

        return ','

    def open_or_create_project(self, project_path, project_exists):
        """æ‰“å¼€ç°æœ‰å·¥ç¨‹æˆ–åˆ›å»ºæ–°å·¥ç¨‹"""
        try:
            if project_path and project_exists:
                print(f"ğŸ”„ æ‰“å¼€ç°æœ‰å·¥ç¨‹: {project_path}")
                op.open(file=project_path)
                self.project_opened = True
                print("âœ… å·¥ç¨‹å·²æ‰“å¼€")
                return True
            else:
                if project_path:
                    print(f"ğŸ“ åˆ›å»ºæ–°å·¥ç¨‹: {project_path}")
                    project_dir = os.path.dirname(project_path)
                    if project_dir:
                        os.makedirs(project_dir, exist_ok=True)
                    op.new(file=project_path)
                    self.project_opened = True
                else:
                    print("ğŸ“ åˆ›å»ºæ–°å·¥ç¨‹")
                    self.project_opened = False

                return True

        except Exception as e:
            print(f"âŒ æ‰“å¼€/åˆ›å»ºå·¥ç¨‹æ—¶å‡ºé”™ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False

    def export_to_origin(self, df, data_filename, project_path=None, project_exists=False):
        """å°†DataFrameå¯¼å‡ºåˆ°Originå·¥ä½œç°¿"""
        try:
            op.set_show(True)

            if not self.open_or_create_project(project_path, project_exists):
                return False

            book_name = self.get_safe_filename(os.path.basename(data_filename))
            sheet_name = f"{book_name}_Sheet"

            print(f"ğŸ“˜ åˆ›å»ºå·¥ä½œç°¿: '{book_name}'")
            print(f"   å¯¼å…¥ {df.shape[1]} åˆ—: {list(df.columns)}")

            # åˆ›å»ºæ–°å·¥ä½œç°¿
            self.wb = op.new_book('w', book_name)
            self.wks = self.wb[0]
            self.wks.name = sheet_name

            # å¯¼å‡ºæ•°æ®åˆ°Origin
            self.wks.from_df(df)

            # è®¾ç½®åˆ—å®½
            print(f"ğŸ”„ è®¾ç½®åˆ—æ ¼å¼...")
            try:
                self.wks.set_col_width(width=15)
                print(f"   å·²è®¾ç½®æ‰€æœ‰åˆ—å®½ä¸º15")
            except:
                try:
                    # å¤‡é€‰æ–¹æ³•ï¼šé€ä¸ªè®¾ç½®åˆ—å®½
                    for i in range(self.wks.cols):
                        self.wks.col(i).width = 15
                    print(f"   å·²é€ä¸ªè®¾ç½®åˆ—å®½ä¸º15")
                except Exception as width_error:
                    print(f"âš ï¸  è®¾ç½®åˆ—å®½å¤±è´¥: {width_error}")

            # æ·»åŠ å•ä½ä¿¡æ¯åˆ°åˆ—æ ‡é¢˜ - ä¿®å¤è¿™é‡Œï¼šä½¿ç”¨ col() è€Œä¸æ˜¯ cols()
            if hasattr(self, 'column_units') and self.column_units:
                print(f"ğŸ“ æ·»åŠ å•ä½ä¿¡æ¯...")
                success_count = 0

                for i, col_name in enumerate(df.columns):
                    if col_name in self.column_units:
                        unit = self.column_units[col_name]

                        try:
                            # è·å–åˆ—å¯¹è±¡ - å…³é”®ä¿®å¤ï¼šä½¿ç”¨ col() æ–¹æ³•
                            col_obj = self.wks._find_col(i)

                            # æ–¹æ³•1ï¼šå°è¯•è®¾ç½®å•ä½
                            try:
                                #col_obj.units = unit
                                col_obj.SetUnits(unit)
                                print(f"   âœ“ åˆ— {i}: {col_name} [å•ä½å±æ€§: {unit}]")
                                success_count += 1
                            except:
                                # æ–¹æ³•2ï¼šå°è¯•è®¾ç½®æ³¨é‡Š
                                try:
                                    col_obj.comments = f"å•ä½: {unit}"
                                    print(f"   âœ“ åˆ— {i}: {col_name} [å•ä½: {unit}]")
                                    success_count += 1
                                except:
                                    # æ–¹æ³•3ï¼šå°è¯•è®¾ç½®é•¿åç§°
                                    try:
                                        col_obj.lname = f"{col_name} ({unit})"
                                        print(f"   âœ“ åˆ— {i}: {col_name} -> {col_name} ({unit})")
                                        success_count += 1
                                    except:
                                        print(f"   âš ï¸ åˆ— {i}: {col_name} - æ‰€æœ‰å•ä½è®¾ç½®æ–¹æ³•éƒ½å¤±è´¥")

                        except Exception as col_error:
                            print(f"   âŒ åˆ— {i}: {col_name} - è·å–åˆ—å¯¹è±¡å¤±è´¥: {col_error}")

                print(f"   æˆåŠŸä¸º {success_count}/{len(self.column_units)} ä¸ªåˆ—æ·»åŠ å•ä½ä¿¡æ¯")
            else:
                print(f"â„¹ï¸  æœªæ‰¾åˆ°åˆ—å•ä½ä¿¡æ¯ï¼Œä½¿ç”¨åŸå§‹åˆ—å")

            # éªŒè¯æ•°æ®å¯¼å…¥æˆåŠŸ
            print(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å…¥Originå·¥ä½œç°¿")
            print(f"   å·¥ä½œç°¿åç§°: {self.wb.name}")
            print(f"   å·¥ä½œè¡¨åç§°: {self.wks.name}")
            print(f"   æ•°æ®ç»´åº¦: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")

            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
            print(f"   å·¥ä½œè¡¨åˆ—æ•°: {self.wks.cols}")
            if self.wks.cols > 0:
                try:
                    test_col = self.wks.col(0)
                    print(f"   ç¬¬0åˆ—å¯¹è±¡ç±»å‹: {type(test_col)}")
                    print(f"   ç¬¬0åˆ—åç§°: {test_col.name}")
                except Exception as debug_e:
                    print(f"   è·å–ç¬¬0åˆ—ä¿¡æ¯å¤±è´¥: {debug_e}")

            return True

        except Exception as e:
            print(f"âŒ å¯¼å‡ºåˆ°Originæ—¶å‡ºé”™ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False

    def plot_in_origin(self, x_col, y_col, output_path, save_project=True, project_path=None):
        """åœ¨Originä¸­ç»˜åˆ¶å›¾å½¢"""
        try:
            # è·å–åˆ—ç´¢å¼• - ä¿®å¤è¿™é‡Œï¼šä½¿ç”¨ col() è€Œä¸æ˜¯ cols()
            try:
                col_names = [self.wks.col(i).name for i in range(self.wks.cols)]
            except AttributeError:
                # å¤‡é€‰æ–¹æ³•ï¼šå¦‚æœ name å±æ€§ä¸å¯ç”¨
                col_names = []
                for i in range(self.wks.cols):
                    try:
                        col_names.append(self.wks.col(i).name)
                    except:
                        # å¦‚æœæ— æ³•è·å–åˆ—åï¼Œä½¿ç”¨é»˜è®¤åç§°
                        col_names.append(f"Col_{i + 1}")

            print(f"ğŸ“Š å·¥ä½œè¡¨åˆ—å: {col_names}")

            if x_col not in col_names:
                print(f"âŒ æ•°æ®ä¸­ä¸å­˜åœ¨Xè½´åˆ— '{x_col}'")
                print(f"   å¯ç”¨åˆ—: {col_names}")
                return False

            if y_col not in col_names:
                print(f"âŒ æ•°æ®ä¸­ä¸å­˜åœ¨Yè½´åˆ— '{y_col}'")
                print(f"   å¯ç”¨åˆ—: {col_names}")
                return False

            x_idx = col_names.index(x_col)
            y_idx = col_names.index(y_col)

            print(f"âœ… æ‰¾åˆ°åˆ—ä½ç½®: {x_col}[ç´¢å¼•{x_idx}], {y_col}[ç´¢å¼•{y_idx}]")

            # ç”ŸæˆGraphåç§°
            graph_name = f"{y_col}-{x_col}"
            print(f"ğŸ“ˆ åˆ›å»ºGraph: '{graph_name}'")

            # æ£€æŸ¥Graphæ˜¯å¦å·²å­˜åœ¨
            try:
                existing_graphs = op.lt_graph()
                if existing_graphs and graph_name in existing_graphs:
                    import time
                    timestamp = time.strftime("%H%M%S")
                    graph_name = f"{graph_name}_{timestamp}"
            except:
                pass

            # åˆ›å»ºå›¾å½¢
            self.graph = op.new_graph(template='line')

            # è®¾ç½®Graphåç§°
            try:
                self.graph.name = graph_name
            except:
                print(f"âš ï¸  æ— æ³•è®¾ç½®Graphåç§°ï¼Œä½¿ç”¨é»˜è®¤åç§°")

            gl = self.graph[0]

            # æ·»åŠ ç»˜å›¾
            try:
                plot = gl.add_plot(self.wks, coly=y_idx, colx=x_idx, type='line')
                print(f"âœ… æˆåŠŸæ·»åŠ ç»˜å›¾: {y_col} vs {x_col}")
            except Exception as plot_error:
                print(f"âŒ æ·»åŠ ç»˜å›¾æ—¶å‡ºé”™: {plot_error}")
                # å°è¯•å¤‡é€‰æ–¹æ³•
                try:
                    plot = gl.add_plot(self.wks, coly=y_idx, colx=x_idx)
                    print(f"âœ… ä½¿ç”¨å¤‡é€‰æ–¹æ³•æ·»åŠ ç»˜å›¾æˆåŠŸ")
                except:
                    return False

            # è®¾ç½®å›¾å½¢å±æ€§
            gl.rescale()
            gl.label('X').text = x_col
            gl.label('Y').text = y_col
            gl.title = f'{y_col} vs {x_col}'

            # è®¾ç½®çº¿æ¡æ ·å¼
            try:
                plot.color = '#FF6600'  # æ©™è‰²
                plot.width = 2
            except:
                print(f"âš ï¸  æ— æ³•è®¾ç½®çº¿æ¡æ ·å¼ï¼Œä½¿ç”¨é»˜è®¤æ ·å¼")

            print(f"âœ… Graph '{graph_name}' åˆ›å»ºæˆåŠŸ")

            # ä¿å­˜å›¾å½¢
            try:
                self.graph.save_fig(output_path)
                print(f"âœ… å›¾å½¢å·²ä¿å­˜ä¸ºPNG: {output_path}")
            except Exception as save_error:
                print(f"âŒ ä¿å­˜å›¾å½¢æ—¶å‡ºé”™: {save_error}")
                return False

            # ä¿å­˜å·¥ç¨‹
            if save_project and project_path:
                try:
                    op.save(project_path)
                    print(f"âœ… å·¥ç¨‹æ–‡ä»¶å·²ä¿å­˜: {project_path}")
                except Exception as save_project_error:
                    print(f"âš ï¸  ä¿å­˜å·¥ç¨‹æ–‡ä»¶æ—¶å‡ºé”™: {save_project_error}")
                    # å°è¯•å¦å­˜ä¸º
                    try:
                        backup_path = output_path.replace('.png', '_backup.opju')
                        op.save(backup_path)
                        print(f"âœ… å·¥ç¨‹æ–‡ä»¶å·²å¦å­˜ä¸º: {backup_path}")
                    except:
                        print(f"âš ï¸  æ— æ³•ä¿å­˜å·¥ç¨‹æ–‡ä»¶ï¼Œè¯·åœ¨Originä¸­æ‰‹åŠ¨ä¿å­˜")

            return True

        except Exception as e:
            print(f"âŒ ç»˜å›¾æ—¶å‡ºé”™ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False

    def save_project_as(self, file_path):
        """å¦å­˜å·¥ç¨‹æ–‡ä»¶"""
        try:
            op.save(file_path)
            print(f"âœ… å·¥ç¨‹å·²å¦å­˜ä¸º: {file_path}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å·¥ç¨‹æ—¶å‡ºé”™ï¼š{e}")
            return False

    def close_origin(self):
        """å…³é—­Originè¿æ¥"""
        try:
            pass
        except:
            pass


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¢ æ™ºèƒ½Originæ•°æ®å¤„ç†ä¸ç»˜å›¾ç³»ç»Ÿ")
    print("=" * 60)

    processor = OriginDataProcessor()

    if len(sys.argv) > 1:
        config_file = sys.argv[1]
        print(f"ğŸ“‹ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„é…ç½®æ–‡ä»¶: {config_file}")
    else:
        config_file = "OriginBook/plog_config.json"
        print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤é…ç½®æ–‡ä»¶: {config_file}")

    processor._config_dir = os.path.dirname(os.path.abspath(config_file)) if os.path.exists(
        config_file) else os.getcwd()

    try:
        # 1. åŠ è½½é…ç½®
        print("\nğŸ“‹ æ­¥éª¤1: åŠ è½½ç»˜å›¾é…ç½®")
        config = processor.load_config(config_file)
        if not config:
            return False

        if not os.path.exists(config['data_file']):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {config['data_file']}")
            return False

        graph_expected_name = f"{config['Y']}-{config['X']}"
        print(f"ğŸ“Š é¢„æœŸç”Ÿæˆçš„Graphåç§°: '{graph_expected_name}'")

        # 2. è¯»å–æ•°æ®æ–‡ä»¶
        print(f"\nğŸ“Š æ­¥éª¤2: è¯»å–æ•°æ®æ–‡ä»¶")
        need_columns = config.get('NeedCol')

        if need_columns:
            print(f"   é…ç½®è¦æ±‚æå–åˆ—: {need_columns}")

        df, columns, success = processor.read_data_file(config['data_file'], need_columns)
        if not success:
            return False

        # 3. å¯¼å‡ºåˆ°Origin
        print(f"\nğŸ”„ æ­¥éª¤3: å¯¼å‡ºæ•°æ®åˆ°Origin")

        project_path = config.get('project')
        project_exists = config.get('project_exists', False)

        export_success = processor.export_to_origin(
            df,
            data_filename=config['data_file'],
            project_path=project_path,
            project_exists=project_exists
        )

        if not export_success:
            return False

        # 4. ç»˜åˆ¶å›¾å½¢
        print(f"\nğŸ“ˆ æ­¥éª¤4: æ ¹æ®é…ç½®ç»˜åˆ¶å›¾å½¢")
        print(f"   å°†ç”ŸæˆGraph: '{graph_expected_name}'")

        data_basename = os.path.splitext(os.path.basename(config['data_file']))[0]
        output_dir = config['output_dir']
        png_output_path = os.path.join(output_dir, f"{data_basename}_plot.png")

        plot_success = processor.plot_in_origin(
            x_col=config['X'],
            y_col=config['Y'],
            output_path=png_output_path,
            save_project=True,
            project_path=project_path if project_exists else None
        )

        # 5. ä¿å­˜æ–°å·¥ç¨‹
        if not project_exists and project_path and plot_success:
            if not any(project_path.endswith(ext) for ext in ['.opj', '.opju']):
                project_path = project_path + '.opju'

            os.makedirs(os.path.dirname(project_path) or '.', exist_ok=True)

            try:
                op.save(project_path)
                print(f"âœ… æ–°å·¥ç¨‹æ–‡ä»¶å·²ä¿å­˜: {project_path}")
            except Exception as e:
                print(f"âŒ ä¿å­˜æ–°å·¥ç¨‹æ–‡ä»¶æ—¶å‡ºé”™: {e}")

        # 6. æ˜¾ç¤ºç»“æœ
        print(f"\n{'=' * 60}")
        if plot_success:
            print("ğŸ‰ å¤„ç†å®Œæˆï¼")
            print(f"   æ•°æ®æ–‡ä»¶: {config['data_file']}")
            print(f"   é…ç½®: X={config['X']}, Y={config['Y']}")
            print(f"   å·¥ä½œç°¿: åŸºäº '{os.path.basename(config['data_file'])}' å‘½å")
            print(f"   Graph: '{graph_expected_name}'")
            print(f"   è¾“å‡ºå›¾å½¢: {png_output_path}")

            if project_path:
                if project_exists:
                    print(f"   å·¥ç¨‹æ–‡ä»¶: {project_path} (å·²æ›´æ–°)")
                else:
                    print(f"   å·¥ç¨‹æ–‡ä»¶: {project_path} (å·²åˆ›å»º)")
        else:
            print("âš ï¸  æ•°æ®å¤„ç†å®Œæˆï¼Œä½†ç»˜å›¾å¤±è´¥")
            print("   æ•°æ®å·²ä¿å­˜åˆ°Originå·¥ä½œç°¿ï¼Œè¯·æ‰‹åŠ¨ç»˜å›¾")

        print("\nğŸ’¡ æç¤ºï¼š")
        print("1. æ”¯æŒå¤æ‚çš„åŒåˆ—åå®šä¹‰æ ¼å¼")
        print("2. è‡ªåŠ¨æå–å¹¶åº”ç”¨åˆ—å•ä½ä¿¡æ¯")
        print("3. ä»¥DataNameè¡Œçš„åˆ—é¡ºåºä¸ºå‡†")

        return plot_success

    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        processor.close_origin()


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
